---
title: "ML on the Iris Dataset"
author: "Ted Laderas"
date: "May 23, 2016"
output: html_document
---

In this Markdown document, I show how to run Linear Discriminant Analysis (LDA) and Classification Trees on the dataset. 

Your number one step is to try using `knitr` to build this document and view the output. Use the `Knit HTML` button right above the source window. For the workshop, you will be modifying two different Markdown documents (`ldaAssignment.Rmd` and `CTreeAssignment.Rmd`) to share your work.

The first step is to reduce the Iris dataset to a 2-class problem, to make it easier to understand. We'll use this dataset on the Classification Tree algorithm as well.

```{r message=FALSE}
set.seed(11111)
library(dplyr)
data(iris)

#select only "versicolor" and "virginica" species from data
#we need to recast Species as a factor to drop the "versicolor" level
iris2 <- iris %>% filter(Species %in% c("versicolor", "virginica")) %>% mutate(Species = factor(Species))

#confirm that we did the subsetting correct
summary(iris2)
```

Here we subset the data by building a training set to train our learner, and holding out part of the data to assess the performance on the dataset. Note that you won't have to do this on the Breast Cancer Dataset, since we've already separated the two out.

```{r}
dataSize <- nrow(iris2)
#build a training set of 80% of the testSet
trainSetSize <- floor(0.8 * dataSize)

#build our training set, by sampling from the number of rows randomly to select rows
trainDataIndices <- sample(1:dataSize, size=trainSetSize)

#select the rows
trainData <- iris2[trainDataIndices,]
#confirm the number of rows should be 80
nrow(trainData)

#build our test set using the R-indexing
#using the "-" operator
testData <- iris2[-trainDataIndices,]

#confirm the number of rows (should be 20)
nrow(testData)
```

#Running the LDA algorithm

Here I run LDA on the `iris` dataset using the `lda()` function in the MASS package. I use the formula interface to specify the class. 

```{r}
#load MASS library (needed for lda())
library(MASS)
#Here, we use the formula interface to specify what the classes are and what the features are.
#The formula should be: 
#Classes = Species
#Features = everything else (specified using ".")
ldaIris <- lda(Species ~ . , data=trainData)

##If we just wanted to run the LDA using Petal.Length and Petal.Width, we'd run it like this:
ldaIris2 <- lda(Species ~ Petal.Length + Petal.Width, data=trainData)
```

Here we plot the LDA object, in order to assess how well it discriminates between the two classes. This is a conditional histogram that shows the value of each sample when projected onto the linear discriminant. Ideally, we want to have all the samples for one class on one side of the histogram and all the samples on the other side of the histogram on the other. Is that the case for this dataset?

```{r}
plot(ldaIris)
```

Let's evaluate the discriminant using `predict()` on the test set. How do we read this table. What is our percent misclassified on the test set? How do we calculate it? (Hint: you can use the `diag()` function to just grab the values from the diagonals).

```{r}
#Evaluate the class predictions on the training data
classPred <- predict(ldaIris, testData)
classPred <- classPred$class

#show the 
confusionMatrix <- table(testData$Species, classPred)
confusionMatrix
```

**Suggested Exercise**: Try running the LDA on the full iris dataset. How well does the LDA work on this problem? How does the output differ?



#Running the Classification Tree algorithm

We'll use the `tree` package to build our classification trees on the training data.

```{r}
library(tree)

trainTree <- tree(Species ~ ., data=trainData)
```

Here we plot the tree that results from the training the tree. Is there anything that you notice?

```{r}
#note that you have to use the text line after the plot command. Otherwise, the plot has no labels!
plot(trainTree)
text(trainTree, all=T)
```

Our tree seems to be a little too complicated, but let's try it on the test dataset. Let's look at the performance of the tree on our test data. What is the percent misclassified?

```{r}
#note that the predict() interface is different for tree objects
testResults <- predict(trainTree, newdata=testData, type="class")
table(testData$Species, testResults)
```

**Suggested Exercise**: try running `tree()` on the full dataset. What does the tree look like? 